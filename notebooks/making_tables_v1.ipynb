{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1 of Tables (Final Final Final Version) - 10/25/2020#\n",
    "\n",
    "major updates include\n",
    "\n",
    "* cleaned sample after cross-matching with JM's siena galaxy atlas\n",
    "  - I matched the VF catalog to SGA using a match radius of 10 arcsec\n",
    "  - 1902 sources did not match\n",
    "    - sources are listed here https://docs.google.com/spreadsheets/d/1l9Ay1NSc7ovFglQCZ3PphaHmXep3LFMcdxCOwrXFHgQ/edit?usp=sharing\n",
    "  - we reviewed each source by eye\n",
    "  - then went back to by_eye classifications to update the codes on any galaxies that should be\n",
    "    - deleted\n",
    "    - recentered\n",
    "    - merged with another galaxy (e.g. alfalfa source with offset coordinates)\n",
    "    \n",
    "  - need to trace back to galnumber in the by-eye spreadsheet\n",
    "  \n",
    "* addition of any sources in Steer catalog with vr < 500 but redshift independent distance > vr/H0\n",
    "  - these will need to have NSA, HL and A100 matches as well :(\n",
    "  - this will require some more thought...\n",
    "  \n",
    "  \n",
    "* remove repeat NED names - this is just a problem with the NED names, not with the actual galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits, ascii\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.table import Table\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.  Comparison with Siena Galaxy Atlas ##\n",
    "\n",
    "**Description:**\n",
    "we have finished reviewing all the galaxies that didn't match to JM's Siena Galaxy Atlas.  The list of matching galaxies is at:\n",
    "https://docs.google.com/spreadsheets/d/1l9Ay1NSc7ovFglQCZ3PphaHmXep3LFMcdxCOwrXFHgQ/edit?usp=sharing\n",
    "\n",
    "**Remedy:**\n",
    "We will update the byeye classification spreadsheet.  The \n",
    "spreadsheet is at\n",
    "\n",
    "https://docs.google.com/spreadsheets/d/1GtvYTBU3tAXI7ngklFWms3WpnGhbzpp3Nn-_VO7sioc/edit?usp=sharing\n",
    "\n",
    "Download as a xlsx file.  Will get saved in ~/Downloads/\n",
    "\n",
    "**Action Items**\n",
    "* need to carry original galnumber from the kitchen_sink through to the vf_clean catalog.\n",
    "* added function add_byeye_galid in clean_kitchen_sink.py to add this column to the cleaned catalog\n",
    "* rerun clean_kitchen_sink.py\n",
    "  * creates vf_clean_sample.fits (9217 lines)\n",
    "* rerun get_NEDname.py\n",
    "  * creates vf_clean_sample_wNEDname.fits (9217 lines)\n",
    "  * previous version had 9214 :(\n",
    "* remove sources that have [KHL2017]S in name - updated byeye spreadsheet accordingly\n",
    "* download updated bye eye spreadsheet and save in research/Virgo/google-tables\n",
    "  * first download latest version of virgo_check_by_eye from google spreadsheet, save as excel file\n",
    "  * move to ~/research/Virgo/google-tables\n",
    "   ```\n",
    "   mv ~/Downloads/virgo_check_sample_by_eye.xlsx virgo_check_sample_by_eye_v1.finished.xlsx\n",
    "   ```\n",
    "  * run this program \n",
    "   ```\n",
    "   python ~/github/Virgo/programs/collate_check_by_eye_results.py\n",
    "   ```\n",
    "  * or from within ipython -pylab\n",
    "```\n",
    "%run ~/github/Virgo/programs/collate_check_by_eye_results.py\n",
    "```\n",
    "* download csv version of updated VF-notin-SGA \n",
    "\n",
    "```\n",
    "mv ~/Downloads/VF-notin-SGA-10arcsecmatch-bestmatch-symmetric\\ -\\ VF-notin-SGA.csv VF-notin-SGA-10arcsecmatch-bestmatch-symmetric.csv\n",
    "\n",
    "```\n",
    "* rerun clean_kitchen_sink.py\n",
    "  * will output v1 of files\n",
    "    * output_catalog = 'vf_clean_sample_v1.fits'\n",
    "    * output_clean = 'clean_sample_v1.fits' # I'm not sure why I have two output files, just a holdover I think\n",
    "    * ipac_table = 'clean_sample_v1.txt'\n",
    "\n",
    "**NOTES**\n",
    "I updated the original classification spreadsheet based on our assessments of the galaxies that don't match JM's catalog.  I need to preserve the kitchen sink catalog b/c this is our last link to the original classification spreadsheet and cutouts.  I am uploading it to the visual classification folder.  This notebook describes how I related VFID in v0 catalogs to the line number in smart_kitchen_sink_v2.fits.  \n",
    "\n",
    "We also noted galaxies that have a radius that was too big or too small.  I am going to incorporate this information into the write_subtables, where we merge different radial size estimates.  Added this to the function get_radius. \n",
    "\n",
    "We updated centers for some galaxies, but JM said not to both b/c his code will figure this out.\n",
    "  \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Update byeye classifications ##\n",
    "\n",
    "* get galnumber for VFID for galaxies in the https://docs.google.com/spreadsheets/d/1l9Ay1NSc7ovFglQCZ3PphaHmXep3LFMcdxCOwrXFHgQ/edit?usp=sharing\n",
    "* update the by-eye classifications https://docs.google.com/spreadsheets/d/1GtvYTBU3tAXI7ngklFWms3WpnGhbzpp3Nn-_VO7sioc/edit?usp=sharing\n",
    "  * updating sheet on 2020-10-25\n",
    "  \n",
    "* having trouble reading the csv file into python - the headers are getting cutout.  This was b/c I had multiple columns with the same name.  Fixed this and now it loads fine.\n",
    "\n",
    "  \n",
    "## 1a - more Details on how I updated the byeye spreadsheet\n",
    "\n",
    "Basically, this involved linking the VFID with the galaxy number in the original spreadsheet\n",
    "\n",
    "* the number in the original spreadsheet is the line number in smart_kitchen_sink.v2.fits\n",
    "* however, when I reran clean_kitchen_sink in Oct 2020, I ended up with 3 extra galaxies (no idea why), and so the VFIDs were different.\n",
    "* figured things out eventually, but I ended up searching for objects by name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what worked in Oct 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badgals = Table.read('/home/rfinn/research/Virgo/google-tables/VF-notin-SGA-10arcsecmatch-bestmatch-symmetric.csv',format='ascii')\n",
    "# keep galaxies that we need to get rid of \n",
    "badflag = badgals['keep?'] == 0\n",
    "badgals = badgals[badflag]\n",
    "sink = Table.read('/home/rfinn/research/Virgo/supersample/smart_kitchen_sink_v2.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkindex = np.arange(len(sink))\n",
    "match_field = ['objname','NSAID','NSAIDV0']\n",
    "sink_field = ['objname','NSAID','NSAID_2']\n",
    "outfile = open('/home/rfinn/research/Virgo/google-tables/byeye-crossmatch-ids.csv','w')\n",
    "for i in range(len(badgals)):\n",
    "    matchflag=False\n",
    "    for j in range(len(match_field)):\n",
    "        gname = badgals[match_field[j]][i]\n",
    "        if (gname != 'N/A'):# & (gname != 0):\n",
    "            gflag = sink[sink_field[j]] == gname\n",
    "            if sum(gflag) == 1:\n",
    "                #print(badgals['VFID'][i],sinkindex[gflag][0])\n",
    "                s = '%s, %i \\n'%(badgals['VFID'][i],sinkindex[gflag][0])\n",
    "                outfile.write(s)\n",
    "                matchflag=True\n",
    "                break\n",
    "            elif sum(gflag) == 2:\n",
    "                print(badgals['VFID'][i],sinkindex[gflag])\n",
    "                s = '%s, %i, %i \\n'%(badgals['VFID'][i],sinkindex[gflag][0],sinkindex[gflag][0])\n",
    "                outfile.write(s)\n",
    "                matchflag=True\n",
    "            elif sum(gflag) > 1:\n",
    "                pass\n",
    "        \n",
    "    if not(matchflag):\n",
    "        #print('HELP!!! no match for',badgals['VFID'][i],gname)\n",
    "        print(badgals['VFID'][i],-999)\n",
    "        outfile.write('%s, %i \\n'%(badgals['VFID'][i],-999))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Make new version of cleaned kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# got an error because indices in clean_new_a100 pointed to old indices\n",
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/clean_kitchen_sink.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated code to review a100 galaxies #\n",
    "\n",
    "* previously, I had run check_new_a100 to review the a100 galaxies that were added.  \n",
    "* the function clean_new_a100 got rid of the duplicates, or merged them with the correct parent\n",
    "\n",
    "```\n",
    "        child = np.array([7423, 9207, 9209, 8952],'i')\n",
    "        parent = np.array([9206, 6575, 6638, 9213],'i')\n",
    "        for i in range(len(child)):\n",
    "            print('merging {} with {}'.format(child[i],parent[i]))\n",
    "            self.merge_sources(parent[i],child[i],cat=self.clean_a100,HL=False,NSA=False,AGC=False,A100=True)\n",
    "            self.clean_a100['A100flag'][parent[i]] = True\n",
    "```\n",
    "\n",
    "* the updated catalog has different order, so now I have to redo the a100 match\n",
    "\n",
    "* moving forward, I should match by some name rather than array index, in case we update the catalog again.\n",
    "\n",
    "\n",
    "### Solution\n",
    "\n",
    "* The solution is to uncomment **def check_new_a100** and comment out the rest of **runall**\n",
    "* review the galaxies\n",
    "* if they are part of a galaxy that is already in the catalog, then merge the sources.  if we have a new version, then the index numbers will need to be updated in the function **clean_new_a100**\n",
    "\n",
    "### NOTE\n",
    "* I also fixed an error in the allgals function - the y coordinate in the jpeg image was set to the y value that comes from the conversion from RA and DEC, but it needs to be y_image_size - y for the jpeg image.  I had fixed this in mksupersample.py, but didn't fix this in clean_kitchen_sink.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# running with check_new_a100\n",
    "# and the rest of runall commented out\n",
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/clean_kitchen_sink.py\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# running with check_new_a100\n",
    "# with image size = 90 arcsec\n",
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/clean_kitchen_sink.py\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After updating indices of AGC-only sources that need to be merged\n",
    "\n",
    "* you get the indices from the cutout images (and the printout of which images are in FOV, if text overlaps or is hard to read)\n",
    "* uncomment the rest of runall, and comment out check_new_a100\n",
    "* Then run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/clean_kitchen_sink.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  BV has found ##\n",
    "\n",
    "* galaxies in Steer with vr< 500 but redshift-independent distances that are consistent with our cut\n",
    "* a few from EVCC that are not included (from Kim paper)\n",
    "* these need to be added to the catalog\n",
    "* these additional galaxies include all but one of GL's 245 CO galaxies\n",
    "  * IC 3094 is not included.  It's redshift independent distance corresponds to a vr = 3478 (H0=74), so this shouldn't be in the sample.\n",
    "    - it's in the steer catalog\n",
    "    - vcomic = -237 km/s\n",
    "  * followed up with Gianluca, and this should NOT be included, so we are ok\n",
    "* file is in \n",
    "```\n",
    "research/Virgo/ancil-tables/Steer_EVCC_toadd_fromBV_2020Oct27.fits  \n",
    "```\n",
    "\n",
    "### possible options for implementing\n",
    "\n",
    "* using topcat, match steer catalog to \n",
    "  * HL, agc,NSAv1,NSAv0, a100-sdss-wise to produce a second table with columns that match the clean_kitchen_sink\n",
    "  * stilts - command line version of topcat - could be useful for repeating analysis multiple times\n",
    "\n",
    "* make new version of mksupersample, but use steer catalog as the input instead of HL?\n",
    "\n",
    "* download vr < 500 version of HL catalog, match to catalog of new galaxies (steer + EVCC), then use this as HL catalog in a new version of mksupersample that only matches this catalog to agc, NSAv1, NSAv0\n",
    "  - this catalog could be added in clean_kitchen_sink so that indices of previous sources don't change (for example, when I clean/merge the new a100 sources).  Although maybe this is not the way to go because the \"new\" A100 sources that we find in clean_kitchen_sink might match to one of new sources?\n",
    "  \n",
    "* these galaxies need to be added to the clean_kitchen_sink file\n",
    "  * GL's catalog has HL information\n",
    "  * write a separate program to match to HL, NSAv0, and NSAv1\n",
    "  * a100 matching will happen in clean_kitchen_sink\n",
    "  \n",
    "  \n",
    "### Approach\n",
    "\n",
    "* download new HL catalog, but remove low vr cut\n",
    "\n",
    "```\n",
    " Hyperleda query:  http://leda.univ-lyon1.fr/fullsql.html\n",
    "\n",
    "        parameters described here: http://leda.univ-lyon1.fr/leda/meandata.html\n",
    "\n",
    "        SQL QUERY:\n",
    "        \n",
    "        select\n",
    "        objname,objtype,de2000,al2000,v,e_v,vopt,e_vopt,vrad,e_vrad,bt,e_bt,type,bar,ring,multiple,compactness,t,e_t,logd25,e_logd25,logr25,e_logr25,pa,incl,logdc,btc,itc,ubtc,bvtc,m21c,hic,mabs,agnclass,kt,e_kt,it,e_it,ut,vt,mfir,e_ut,e_vt, modz, e_modz, mod0, e_mod0,vmaxg, e_vmaxg, vmaxs,e_vmaxs,vdis,e_vdis\n",
    "        \n",
    "        where\n",
    "\n",
    "        de2000 > -35 and de2000 < 75 and  al2000 < 280./360.*24.  and al2000 > 100./360.*24. and v < 3300 and objtype='G'\n",
    "\n",
    "        - output as csv, separator is other, ,\n",
    "\n",
    "        delete header lines at beginning and end\n",
    "\n",
    "        2020-10-28: downloaded again but removed the vr > 500 km/s cut.\n",
    "        we are adding galaxies with redshift-independent distances > 500/H0, and \n",
    "        they should be in this updated catalog\n",
    "\n",
    "          - will add this functionality in a separate function\n",
    "\n",
    "```\n",
    "\n",
    "Matched BV's catalog with HL.  Four galaxies don't match\n",
    "\n",
    "|RA | DEC | VH | NOTES |\n",
    "|---|----|-----|-------|\n",
    "| 176.1337 | 6.7041 | 1455.2 | NSA 067042, has a redshift of ~5800 km/ from several sources.  NED says no z-independent distance. AGC 215601 comes up in HL with vr=5700. |\n",
    "|187.8029 | 13.1243 | 1900 | in HL (PGC041416), and they list vr=1900, but they use sdss vr as primary (242316) |\n",
    "| 190.0388 | 6.8837 | 1007 | VCC 1821, PGC 042420.  HL has vr=7300, but it also lists 2 redshifts at 1007km/s |\n",
    "| 195.9078 | 7.904 | 2968 | CGCG 043-122, PGC 045112 and NSA 077423; again HL has vr=13700; sdss redshift is convincing |\n",
    "\n",
    "\n",
    "* Saving file as fits basic, Steer_EVCC_toadd_fromBV_2020Oct27_with_HL.fits, in ~/research/Virgo/ancil-tables\n",
    "\n",
    "* read in table and remove the columns from Benedetta's table so just HL is there.  but first use BV ra, dec and vr if galaxy doesn't match to HL\n",
    "\n",
    "SKIP\n",
    "\n",
    "* edit file to remove header at beginning and end\n",
    "\n",
    "* match BV catalog with Hyperleda column\n",
    "* then match to AGC\n",
    "* then match to NSAv1\n",
    "* then match to NSAv0\n",
    "* add flags\n",
    "* add combined RA, DEC, VEL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = '/home/rfinn/research/Virgo/ancil-tables/Steer_EVCC_toadd_fromBV_2020Oct27_with_HL.fits'\n",
    "tab = Table.read(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tab)):\n",
    "    if tab['objname'][i] == '                            ': # no match to HL\n",
    "        ra = tab['RA'][i]/15. # convert ra from deg to hr\n",
    "        dec = tab['DEC'][i]\n",
    "        tab['al2000'][i] = ra\n",
    "        tab['de2000'][i] = dec\n",
    "        tab['v'][i] = tab['VH'][i]\n",
    "        print('fixing values for gal with no HL match')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only works if you save the sorted table in topcat\n",
    "for i in range(4):\n",
    "    if i == 0:\n",
    "        tab['objname'][i]='AGC215601'\n",
    "    elif i == 1:\n",
    "        tab['objname'][i]='PGC041416'\n",
    "    elif i == 2:\n",
    "        tab['objname'][i]='PGC042420'\n",
    "    elif i == 3:\n",
    "        tab['objname'][i]='PGC045112'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove column\n",
    "col_names = tab.colnames[0:10]\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.remove_columns(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file as a short HL table\n",
    "outfile = '/home/rfinn/research/Virgo/ancil-tables/Steer_EVCC_toadd_HL_cols.fits'\n",
    "tab.write(outfile,format='fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### updated mksupersample\n",
    "\n",
    "it now has --version and --evcc flags\n",
    "\n",
    "* set evcc to read in the file we just wrote, and create an independent smart_kitchen_sink_v2_v1_evcc.fits\n",
    "* version is v1 by default, until we move on to v2 tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/mksupersample.py --evcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=sample()\n",
    "s.get_smart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### woo hoo!!!\n",
    "\n",
    "This worked!  \n",
    "\n",
    "wrote file smart_kitchen_sink_v2_v1_evcc.fits\n",
    "\n",
    "\n",
    "so now the best way forward to append these at the end of vf_clean_sample.fits when reading this in to write_subtables.py\n",
    "\n",
    "nope - need to get NEDname first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/get_NEDname.py --evcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found file ned_names_v1_evcc.fits\n",
      "Using this instead of querying NED\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'superName'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/github/Virgo/programs/get_NEDname.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNED\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vf_clean_sample_v1.fits'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_NEDname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m     \u001b[0;31m#n.query_unmatched()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m#n.write_NEDnames()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Virgo/programs/get_NEDname.py\u001b[0m in \u001b[0;36mget_NEDname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnedfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'found file '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnedfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\nUsing this instead of querying NED'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_NEDname_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/Virgo/programs/get_NEDname.py\u001b[0m in \u001b[0;36mget_NEDname_from_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m#self.clean_a100.rename_column('superName','NEDinput')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_a100\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_a100\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'superName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NEDinput'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# join returns a table that is sorted by the key columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/astropy/table/table.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/astropy/table/table.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'superName'"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/get_NEDname.py --evcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Match catalog to z0MGS\n",
    "\n",
    "* clean_kitchen_sink makes an ipac table in Virgo/supersample called clean_sample_v1.txt\n",
    "* upload this to IRSA https://irsa.ipac.caltech.edu/data/WISE/z0MGS/overview.html\n",
    "  * catalog search Tool\n",
    "  * z0MGS DR1 (not 7.5 arcsec Simple Index)\n",
    "  * gets here https://irsa.ipac.caltech.edu/cgi-bin/Gator/nph-dd\n",
    "  * multi-object search\n",
    "    * 10 arcsec\n",
    "    * 1-to-1 match\n",
    "  * shows results, then click save icon\n",
    "    * save as ipac table.  \n",
    "    ```\n",
    "    cd ~/research/Virgo/tables\n",
    "    mv ~/Downloads/irsa_catalog_search_results_tbl.tbl vf_v1_z0mgs_10arcsec_102620.tbl\n",
    "    ```\n",
    "    * NOTE: we used 30 arcsec last time...\n",
    "  * update filename in write_subtables, get_z0MGS_flag()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Match to NED names ##\n",
    "\n",
    "* need to update input and output files to reflect new version v1\n",
    "* then run the program get_NEDname.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/get_NEDname.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Check to see if all Gianluca's CO sources are in the catalog\n",
    "\n",
    "* from email on 9/22/2020\n",
    "\n",
    "```\n",
    "Hi Rose,\n",
    "\n",
    "thanks for having checked!\n",
    "\n",
    "here are the redshifts from NED : vr>500 km/s means z >~ 0.00166, so none of them are at vr>500 km/s, which is good! The drawback is that now we miss galaxies in the Virgo cluster. I personally find it a bit weird since we are specifically building a catalog of galaxies around Virgo, but if we explain our selection criteria maybe it should be convincing.\n",
    "\n",
    "cheers\n",
    "\n",
    "gianluca\n",
    "\n",
    "1  | |IC 3094                   | -0.000530|   \n",
    "2  | |IC 3476                   | -0.000564|   \n",
    "3  | |MESSIER 059               |  0.001558|   \n",
    "4  | |MESSIER 086               | -0.000747|   \n",
    "5  | |MESSIER 089               |  0.001134|   \n",
    "6  | |MESSIER 090               | -0.000784|   \n",
    "7  | |MESSIER 091               |  0.001621|   \n",
    "8  | |MESSIER 098               | -0.000474|   \n",
    "9  | |NGC 4178                  |  0.001248|   \n",
    "10 | |NGC 4208                  | -0.000270|   \n",
    "11 | |NGC 4216                  |  0.000437|   \n",
    "12 | |NGC 4222                  |  0.000767|   \n",
    "13 | |NGC 4294                  |  0.001184|   \n",
    "14 | |NGC 4312                  |  0.000510|   \n",
    "15 | |NGC 4396                  | -0.000427|   \n",
    "16 | |NGC 4402                  |  0.000774|   \n",
    "17 | |NGC 4407                  |  0.000340|   \n",
    "18 | |NGC 4419                  | -0.000871|   \n",
    "19 | |NGC 4424                  |  0.001458|   \n",
    "20 | |NGC 4438                  |  0.000237|   \n",
    "21 | |NGC 4445                  |  0.001181|   \n",
    "22 | |NGC 4550                  |  0.001531|   \n",
    "23 | |NGC 4634                  |  0.000991|    \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Galaxies that point to the same NED name ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make new version of sub-tables ##\n",
    "* update input filename in write_subtables - masterfile (didn't update this the first time through)\n",
    "\n",
    "* match new table to z0MGS\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "* run write_subtables.py\n",
    "  * run once.  this will generate coords_for_z0MGS.txt\n",
    "  * match to z0MGS using irsa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match to unwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write sub tables\n",
    "\n",
    "# commenting out get_unwise, because I'll have to match to new table\n",
    "os.chdir('/home/rfinn/research/Virgo/supersample/')\n",
    "%run ~/github/Virgo/programs/write_subtables.py --north"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Table.read(homedir+'/research/Virgo/google-tables/VF-notin-SGA-10arcsecmatch-bestmatch-symmetric.csv',format='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t['objname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(t['objname'][17].mask): print('hiya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t['objname'][17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add NED name #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ls ~/research/Virgo/tables-north/v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating other tables\n",
    "\n",
    "* first round through subtables will create a table with\n",
    "  - RA, DEC,\n",
    "\n",
    "* z0MGS\n",
    "\n",
    "* unWISE\n",
    "\n",
    "* cross-match to Tempel catalog \n",
    "  * BV has program to cross match mastertable with Tempel catalog\n",
    "  * create a line-matched table with group 1 and properties of the parent halo for each galaxy that matches to Tempel\n",
    "  * it will also include a field/filament/cluster identifier\n",
    "  \n",
    "* Gianluca's environment table\n",
    "  * where is the best place to put this, does it need to run again?\n",
    "  \n",
    "* legacy photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final step - create main table with flags for all data products\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff - keeping in case it's useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = fits.getdata('/home/rfinn/research/Virgo/supersample/vf_clean_sample.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vfdict = dict((a,b) for a,b in zip(d['VFID'],d['galnumber']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = Table.read('/home/rfinn/research/Virgo/tables-north/v1/vfid-2delete.txt',format='ascii',data_start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old stuff that might be useful, but didn't work for making version 1\n",
    "outfile = open('/home/rfinn/research/Virgo/tables-north/v1/byeyeid-2delete.txt','w')\n",
    "for d in dd:\n",
    "    print(d[0],vfdict[d[0]])\n",
    "    s = str(str(vfdict[d[0]])+'\\n')\n",
    "    outfile.write(s)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
